# Voxel51 Visual Hackathon ğŸ¥‡

This repo contains our first-place-winning project from the **Voxel51 Computer Vision Hackathon at Northeastern**.

## ğŸ”´ Problem
Elderly individuals often struggle to find items or avoid hazards due to poor eyesight, cluttered environments, or cognitive limitations.

## ğŸ§ª Solution
We prototyped an **AR glasses assistant** that:
- Listens for voice queries (â€œWhereâ€™s my white medicine bottle with the orange label?â€)
- Detects objects in the scene using YOLO
- Understands and filters based on the voice prompt using Whisper + CLIPSeg
- Highlights the correct object directly in the video feed

## ğŸ§  Tech Stack
- ğŸ—£ï¸ **OpenAI Whisper** â€” converts speech to text
- ğŸ‘ **YOLO-world** â€” for zero-shot object detection
- ğŸ¯ **CLIPSeg** â€” to align visual embeddings with natural language queries
- ğŸ§± **Python** with OpenCV + custom detection logic

## ğŸ•¶ Workflow
1. Glasses microphone records query
2. Whisper transcribes to text
3. YOLO detects candidate objects
4. CLIPSeg filters & ranks objects based on query
5. Visual overlay highlights correct object

## ğŸ¥ Example Prompts & Results
- â€œFind my white remoteâ€ â†’ highlights white remote in cluttered background  
- â€œWhere are the yellow and blue pillows?â€ â†’ highlights both items  
- â€œSpot the large white sofaâ€ â†’ targets specific furniture in frame

Videos are in `/videos/` â€” see:  
- `where is my remote controller?.mp4`  
- `blue pillow; not the yellow one.mp4`  
- `yellow and blue pillows.mp4`

## ğŸ† Hackathon Outcome
- Built in 24 hours  
- Won **1st place** at Voxel51 Visual AI Hackathon  
- Judged on creativity, real-world utility, and technical depth

## ğŸ‘¥ Team
- Zach Derhake  
- Sidney Ma  
- Ronit Avadhuta  
- Nicholas Yee

Special thanks to **Voxel51** and **Daniel G.** for organizing the event!

## ğŸ—ƒï¸ Repo Structure
